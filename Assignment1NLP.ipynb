{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXuHSqYBPRpo8mQJyu/osA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ananyarishi/NLP/blob/main/Assignment1NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AJ9FXvfpUytx"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hkdwe0DCVNY0",
        "outputId": "cb619c71-0cac-4e3f-8007-7b0c17681a6d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "custom_paragraph = \"Climate change is one of the biggest challenges faced by our planet today. Rising temperatures, melting glaciers, and unpredictable weather patterns are affecting both humans and wildlife. Scientists and researchers are working together to find sustainable solutions that can reduce pollution, conserve resources, and protect future generations.\"\n",
        "print(\"--- Step 0: Original Text ---\")\n",
        "print(custom_paragraph)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqZlsZAAVVBV",
        "outputId": "e2d76118-d364-413b-825e-ff86ddfbb961"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 0: Original Text ---\n",
            "Climate change is one of the biggest challenges faced by our planet today. Rising temperatures, melting glaciers, and unpredictable weather patterns are affecting both humans and wildlife. Scientists and researchers are working together to find sustainable solutions that can reduce pollution, conserve resources, and protect future generations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(custom_paragraph)\n",
        "print(\"--- Step 1: Tokenization ---\")\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2cbeZ0FVc2J",
        "outputId": "34eafe67-a370-4409-8c87-a8e6f5066551"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 1: Tokenization ---\n",
            "['Climate', 'change', 'is', 'one', 'of', 'the', 'biggest', 'challenges', 'faced', 'by', 'our', 'planet', 'today', '.', 'Rising', 'temperatures', ',', 'melting', 'glaciers', ',', 'and', 'unpredictable', 'weather', 'patterns', 'are', 'affecting', 'both', 'humans', 'and', 'wildlife', '.', 'Scientists', 'and', 'researchers', 'are', 'working', 'together', 'to', 'find', 'sustainable', 'solutions', 'that', 'can', 'reduce', 'pollution', ',', 'conserve', 'resources', ',', 'and', 'protect', 'future', 'generations', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word.lower() for word in tokens if word.lower() not in stop_words and word.isalpha()]\n",
        "print(\"--- Step 2: Stopword Removal (and Lowercasing) ---\")\n",
        "print(filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6k6Sn7M5Vjx5",
        "outputId": "1f6483ea-242f-46bc-ffa4-e050bd0b65f3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 2: Stopword Removal (and Lowercasing) ---\n",
            "['climate', 'change', 'one', 'biggest', 'challenges', 'faced', 'planet', 'today', 'rising', 'temperatures', 'melting', 'glaciers', 'unpredictable', 'weather', 'patterns', 'affecting', 'humans', 'wildlife', 'scientists', 'researchers', 'working', 'together', 'find', 'sustainable', 'solutions', 'reduce', 'pollution', 'conserve', 'resources', 'protect', 'future', 'generations']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "stemmed_words = [stemmer.stem(word) for word in filtered_tokens]\n",
        "print(\"--- Step 3: Stemming (Porter Stemmer) ---\")\n",
        "print(stemmed_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSv1nFnkVpiZ",
        "outputId": "96f244ae-9792-43ed-f047-be420b7fdca8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 3: Stemming (Porter Stemmer) ---\n",
            "['climat', 'chang', 'one', 'biggest', 'challeng', 'face', 'planet', 'today', 'rise', 'temperatur', 'melt', 'glacier', 'unpredict', 'weather', 'pattern', 'affect', 'human', 'wildlif', 'scientist', 'research', 'work', 'togeth', 'find', 'sustain', 'solut', 'reduc', 'pollut', 'conserv', 'resourc', 'protect', 'futur', 'gener']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
        "print(\"--- Step 4: Lemmatization (WordNet Lemmatizer) ---\")\n",
        "print(lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPhzqK8FVuLj",
        "outputId": "ed3b6bd1-129f-4371-8a4b-2a7ca2223d92"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Step 4: Lemmatization (WordNet Lemmatizer) ---\n",
            "['climate', 'change', 'one', 'biggest', 'challenge', 'faced', 'planet', 'today', 'rising', 'temperature', 'melting', 'glacier', 'unpredictable', 'weather', 'pattern', 'affecting', 'human', 'wildlife', 'scientist', 'researcher', 'working', 'together', 'find', 'sustainable', 'solution', 'reduce', 'pollution', 'conserve', 'resource', 'protect', 'future', 'generation']\n"
          ]
        }
      ]
    }
  ]
}